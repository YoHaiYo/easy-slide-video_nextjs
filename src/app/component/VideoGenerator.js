"use client";
import { useState } from "react";
import { FFmpeg } from "@ffmpeg/ffmpeg";
import { fetchFile, toBlobURL } from "@ffmpeg/util";

export default function VideoGenerator({
  images,
  settings,
  musicFiles,
  subtitle,
  imageSubtitles,
  isGenerating,
  setIsGenerating,
  onPrev,
}) {
  const [generationProgress, setGenerationProgress] = useState(0);
  const [generatedVideoUrl, setGeneratedVideoUrl] = useState(null);
  const [ffmpeg, setFFmpeg] = useState(null);
  const [isFFmpegLoaded, setIsFFmpegLoaded] = useState(false);
  const [generationStatus, setGenerationStatus] = useState(""); // ìƒì„± ìƒíƒœ ë©”ì‹œì§€
  const [conversionProgress, setConversionProgress] = useState(0); // ë³€í™˜ ì§„í–‰ë¥ 
  const [isInitializing, setIsInitializing] = useState(false); // ì´ˆê¸°í™” ìƒíƒœ

  const handleGenerateVideo = async () => {
    const startTime = performance.now();
    console.log("ğŸ¬ ì˜ìƒ ìƒì„± ì‹œì‘");
    setIsGenerating(true);
    setIsInitializing(true);
    setGenerationProgress(0);
    setGenerationStatus("Starting video generation...");
    setConversionProgress(0);

    try {
      console.log("ğŸ“ Canvas ìƒì„± ì¤‘...");
      // Canvas ìƒì„±
      const canvas = document.createElement("canvas");
      const ctx = canvas.getContext("2d");

      // ì˜ìƒ í•´ìƒë„ ì„¤ì • (16:9 ë¹„ìœ¨) - ì†ë„ ìµœì í™”ë¥¼ ìœ„í•´ 480p ì‚¬ìš©
      const videoWidth = 854;
      const videoHeight = 480;
      canvas.width = videoWidth;
      canvas.height = videoHeight;
      console.log(`ğŸ“ Canvas ì„¤ì • ì™„ë£Œ: ${videoWidth}x${videoHeight}`);

      // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ìƒì„± (ìŒì•…ìš©)
      let audioContext = null;
      let audioBuffers = [];
      let audioSources = [];

      if (musicFiles && musicFiles.length > 0) {
        console.log(`ğŸµ ${musicFiles.length}ê°œ ìŒì•… íŒŒì¼ ì²˜ë¦¬ ì‹œì‘...`);
        try {
          audioContext = new (window.AudioContext ||
            window.webkitAudioContext)();
          console.log("ğŸµ AudioContext ìƒì„± ì™„ë£Œ");

          // ëª¨ë“  ìŒì•… íŒŒì¼ ì²˜ë¦¬
          for (let i = 0; i < musicFiles.length; i++) {
            const musicFile = musicFiles[i];
            console.log(`ğŸµ ìŒì•… ${i + 1} ì²˜ë¦¬ ì¤‘: ${musicFile.name}`);

            const arrayBuffer = await musicFile.file.arrayBuffer();
            console.log(
              `ğŸµ ìŒì•… íŒŒì¼ ${i + 1} ë¡œë“œ ì™„ë£Œ: ${arrayBuffer.byteLength} bytes`
            );

            let audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
            console.log(
              `ğŸµ ì˜¤ë””ì˜¤ ë””ì½”ë”© ì™„ë£Œ: ${audioBuffer.duration}ì´ˆ, ${audioBuffer.sampleRate}Hz`
            );

            // ì‚¬ìš©ì ì§€ì • ê¸¸ì´ê°€ ìˆìœ¼ë©´ ì˜¤ë””ì˜¤ë¥¼ ìë¥´ê¸°
            if (
              musicFile.customDuration &&
              musicFile.customDuration < audioBuffer.duration
            ) {
              console.log(
                `ğŸµ ì˜¤ë””ì˜¤ ê¸¸ì´ ì¡°ì •: ${audioBuffer.duration}ì´ˆ â†’ ${musicFile.customDuration}ì´ˆ`
              );
              const newLength =
                musicFile.customDuration * audioBuffer.sampleRate;
              const newBuffer = audioContext.createBuffer(
                audioBuffer.numberOfChannels,
                newLength,
                audioBuffer.sampleRate
              );

              for (
                let channel = 0;
                channel < audioBuffer.numberOfChannels;
                channel++
              ) {
                const originalData = audioBuffer.getChannelData(channel);
                const newData = newBuffer.getChannelData(channel);
                for (let j = 0; j < newLength; j++) {
                  newData[j] = originalData[j];
                }
              }
              audioBuffer = newBuffer;
            }

            audioBuffers.push(audioBuffer);
          }

          console.log(`ğŸµ ì´ ${audioBuffers.length}ê°œ ìŒì•… íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ`);
        } catch (audioError) {
          console.warn("ğŸµ Audio processing failed:", audioError);
        }
      } else {
        console.log("ğŸµ ìŒì•… íŒŒì¼ ì—†ìŒ - ì˜¤ë””ì˜¤ ì—†ì´ ì§„í–‰");
      }

      // MediaRecorder ì„¤ì • (ì˜¤ë””ì˜¤ í¬í•¨)
      console.log("ğŸ“¹ Canvas ìŠ¤íŠ¸ë¦¼ ìƒì„± ì¤‘...");
      const canvasStream = canvas.captureStream(5); // 5fpsë¡œ ëŒ€í­ ë‚®ì¶¤ (ì •ì§€ ì´ë¯¸ì§€ ìµœì í™”)
      console.log("ğŸ“¹ Canvas ìŠ¤íŠ¸ë¦¼ ìƒì„± ì™„ë£Œ (5fps)");

      // ì˜¤ë””ì˜¤ íŠ¸ë™ ì¶”ê°€
      if (audioContext && audioBuffers.length > 0) {
        console.log("ğŸµ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì„¤ì • ì¤‘...");
        const audioDestination = audioContext.createMediaStreamDestination();

        // ëª¨ë“  ìŒì•…ì„ ìˆœì°¨ì ìœ¼ë¡œ ì—°ê²°
        let currentTime = 0;
        for (let i = 0; i < audioBuffers.length; i++) {
          const audioSource = audioContext.createBufferSource();
          audioSource.buffer = audioBuffers[i];
          audioSource.connect(audioDestination);
          audioSource.start(currentTime);
          audioSources.push(audioSource);

          currentTime += audioBuffers[i].duration;
          console.log(
            `ğŸµ ìŒì•… ${i + 1} ì—°ê²° ì™„ë£Œ, ì‹œì‘ ì‹œê°„: ${
              currentTime - audioBuffers[i].duration
            }ì´ˆ`
          );
        }

        console.log("ğŸµ ëª¨ë“  ì˜¤ë””ì˜¤ ì†ŒìŠ¤ ì—°ê²° ì™„ë£Œ");

        // ì˜¤ë””ì˜¤ì™€ ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ê²°í•©
        const combinedStream = new MediaStream([
          ...canvasStream.getVideoTracks(),
          ...audioDestination.stream.getAudioTracks(),
        ]);
        console.log("ğŸµ ë¹„ë””ì˜¤+ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ê²°í•© ì™„ë£Œ");

        var stream = combinedStream;
      } else {
        console.log("ğŸ“¹ ë¹„ë””ì˜¤ ì „ìš© ìŠ¤íŠ¸ë¦¼ ì‚¬ìš©");
        var stream = canvasStream;
      }

      // ë¸Œë¼ìš°ì € í˜¸í™˜ì„±ì„ ìœ„í•œ MIME íƒ€ì… ì„ íƒ - MP4 ìš°ì„  ì‹œë„
      console.log("ğŸ”§ MediaRecorder MIME íƒ€ì… í™•ì¸ ì¤‘...");
      let mimeType = "video/mp4;codecs=avc1,mp4a"; // MP4 ìš°ì„  ì‹œë„
      let useFFmpeg = false;

      if (!MediaRecorder.isTypeSupported(mimeType)) {
        console.log("âš ï¸ MP4 ë¯¸ì§€ì›, WebM VP9+Opus ì‹œë„");
        mimeType = "video/webm;codecs=vp9,opus";
        if (!MediaRecorder.isTypeSupported(mimeType)) {
          console.log("âš ï¸ VP9+Opus ë¯¸ì§€ì›, VP8+Opus ì‹œë„");
          mimeType = "video/webm;codecs=vp8,opus";
          if (!MediaRecorder.isTypeSupported(mimeType)) {
            console.log("âš ï¸ VP8+Opus ë¯¸ì§€ì›, ê¸°ë³¸ WebM ì‚¬ìš©");
            mimeType = "video/webm";
          }
        }
        useFFmpeg = true; // WebM ì‚¬ìš© ì‹œ FFmpeg ë³€í™˜ í•„ìš”
      }
      console.log(`âœ… ì‚¬ìš©í•  MIME íƒ€ì…: ${mimeType}`);
      console.log(`ğŸ”„ FFmpeg ë³€í™˜ í•„ìš”: ${useFFmpeg ? "Yes" : "No"}`);

      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: mimeType,
        videoBitsPerSecond: 1000000, // 1Mbpsë¡œ ë‚®ì¶¤ (ì†ë„ ìµœì í™”)
        audioBitsPerSecond: 96000, // 96kbpsë¡œ ë‚®ì¶¤
      });
      console.log("ğŸ“¹ MediaRecorder ì„¤ì • ì™„ë£Œ");

      const chunks = [];
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunks.push(event.data);
          console.log(
            `ğŸ“¦ ë°ì´í„° ì²­í¬ ìˆ˜ì‹ : ${event.data.size} bytes (ì´ ${chunks.length}ê°œ)`
          );
        }
      };

      mediaRecorder.onstop = async () => {
        console.log("ğŸ›‘ MediaRecorder ì •ì§€ë¨");
        const videoBlob = new Blob(chunks, { type: mimeType });
        console.log(
          `ğŸ“¦ ë¹„ë””ì˜¤ Blob ìƒì„± ì™„ë£Œ: ${videoBlob.size} bytes (${mimeType})`
        );

        // MP4ê°€ ì§ì ‘ ìƒì„±ëœ ê²½ìš° FFmpeg ë³€í™˜ ìƒëµ
        if (!useFFmpeg) {
          const endTime = performance.now();
          const generationTime = ((endTime - startTime) / 1000).toFixed(2);
          console.log("âœ… MP4 ì§ì ‘ ìƒì„± ì™„ë£Œ - FFmpeg ë³€í™˜ ë¶ˆí•„ìš”");
          console.log(`â±ï¸ ì´ ì˜ìƒ ìƒì„± ì‹œê°„: ${generationTime}ì´ˆ`);
          setGenerationStatus("Video generation completed!");
          const url = URL.createObjectURL(videoBlob);
          setGeneratedVideoUrl(url);
          setIsGenerating(false);
          setGenerationProgress(100);
          console.log("ğŸ‰ ì˜ìƒ ìƒì„± ì™„ì „ ì™„ë£Œ! (MP4 ì§ì ‘ ìƒì„±)");
          return;
        }

        // WebMì¸ ê²½ìš°ì—ë§Œ MP4ë¡œ ë³€í™˜
        setGenerationStatus("Converting WebM to MP4...");
        try {
          console.log("ğŸ”„ WebM â†’ MP4 ë³€í™˜ ì‹œì‘...");
          setConversionProgress(10);

          // ë³€í™˜ ê³¼ì •ì—ì„œ ì§„í–‰ë¥  ì‹œë®¬ë ˆì´ì…˜
          const conversionInterval = setInterval(() => {
            setConversionProgress((prev) => {
              if (prev >= 90) return prev;
              return prev + Math.random() * 5; // ë” ì²œì²œíˆ ì¦ê°€
            });
          }, 800);

          const mp4Blob = await convertWebMToMP4(videoBlob);
          clearInterval(conversionInterval);
          setConversionProgress(100);
          const endTime = performance.now();
          const generationTime = ((endTime - startTime) / 1000).toFixed(2);
          console.log(`âœ… MP4 ë³€í™˜ ì™„ë£Œ: ${mp4Blob.size} bytes`);
          console.log(`â±ï¸ ì´ ì˜ìƒ ìƒì„± ì‹œê°„: ${generationTime}ì´ˆ`);
          setGenerationStatus("Video generation completed!");
          const url = URL.createObjectURL(mp4Blob);
          setGeneratedVideoUrl(url);
          setIsGenerating(false);
        } catch (conversionError) {
          console.warn(
            "âŒ MP4 conversion failed, using WebM:",
            conversionError
          );
          setConversionProgress(100);
          const endTime = performance.now();
          const generationTime = ((endTime - startTime) / 1000).toFixed(2);
          console.log(`â±ï¸ ì´ ì˜ìƒ ìƒì„± ì‹œê°„: ${generationTime}ì´ˆ`);
          setGenerationStatus("Video generation completed! (WebM format)");
          const url = URL.createObjectURL(videoBlob);
          setGeneratedVideoUrl(url);
          setIsGenerating(false);
        }

        setGenerationProgress(100);
        console.log("ğŸ‰ ì˜ìƒ ìƒì„± ì™„ì „ ì™„ë£Œ!");
      };

      // ì˜ìƒ ë…¹í™” ì‹œì‘
      console.log("â–¶ï¸ ì˜ìƒ ë…¹í™” ì‹œì‘...");
      setGenerationStatus("Starting video recording...");
      mediaRecorder.start();

      // ì´ë¯¸ì§€ ë¡œë“œ ë° ë Œë”ë§
      console.log("ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¡œë”© ì‹œì‘...");
      setGenerationStatus("Loading images...");
      const totalDuration = images.length * settings.duration;
      const frameRate = 5; // 5fpsë¡œ ëŒ€í­ ë‚®ì¶¤ (ì •ì§€ ì´ë¯¸ì§€ ìµœì í™”)
      const totalFrames = totalDuration * frameRate;
      console.log(
        `ğŸ“Š ì˜ìƒ ì •ë³´: ${images.length}ì¥, ${totalDuration}ì´ˆ, ${totalFrames}í”„ë ˆì„`
      );

      let currentFrame = 0;
      let currentImageIndex = 0;
      let imageStartFrame = 0;

      // ì´ë¯¸ì§€ í”„ë¦¬ë¡œë“œ
      console.log(`ğŸ–¼ï¸ ${images.length}ê°œ ì´ë¯¸ì§€ í”„ë¦¬ë¡œë“œ ì¤‘...`);
      const loadedImages = await Promise.all(
        images.map((img, index) => {
          return new Promise((resolve) => {
            const image = new Image();
            image.onload = () => {
              console.log(`âœ… ì´ë¯¸ì§€ ${index + 1} ë¡œë“œ ì™„ë£Œ: ${img.name}`);
              resolve(image);
            };
            image.onerror = () => {
              console.error(`âŒ ì´ë¯¸ì§€ ${index + 1} ë¡œë“œ ì‹¤íŒ¨: ${img.name}`);
              resolve(null);
            };
            image.src = img.preview;
          });
        })
      );
      console.log(
        `ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¡œë”© ì™„ë£Œ: ${loadedImages.filter((img) => img).length}/${
          images.length
        }ê°œ ì„±ê³µ`
      );

      // ìŒì•… ì¬ìƒ ì‹œì‘ (ì´ë¯¸ ìœ„ì—ì„œ ì‹œì‘ë¨)
      if (audioSources.length > 0) {
        console.log(`ğŸµ ${audioSources.length}ê°œ ìŒì•… ì¬ìƒ ì‹œì‘...`);
      }

      console.log("ğŸ¨ ì˜ìƒ ë Œë”ë§ ì‹œì‘...");
      setGenerationStatus("Rendering video...");
      setIsInitializing(false); // ì´ˆê¸°í™” ì™„ë£Œ

      const renderFrame = () => {
        // ë°°ê²½ì„ ê²€ì€ìƒ‰ìœ¼ë¡œ í´ë¦¬ì–´
        ctx.fillStyle = "#000000";
        ctx.fillRect(0, 0, videoWidth, videoHeight);

        if (loadedImages.length > 0 && loadedImages[currentImageIndex]) {
          const currentImage = loadedImages[currentImageIndex];
          const imageDuration = settings.duration * frameRate;

          // ì´ë¯¸ì§€ í¬ê¸° ê³„ì‚° (ë¹„ìœ¨ ìœ ì§€)
          const imageAspect = currentImage.width / currentImage.height;
          const canvasAspect = videoWidth / videoHeight;

          let drawWidth, drawHeight, drawX, drawY;

          if (imageAspect > canvasAspect) {
            // ì´ë¯¸ì§€ê°€ ë” ë„“ìŒ
            drawHeight = videoHeight;
            drawWidth = drawHeight * imageAspect;
            drawX = (videoWidth - drawWidth) / 2;
            drawY = 0;
          } else {
            // ì´ë¯¸ì§€ê°€ ë” ë†’ìŒ
            drawWidth = videoWidth;
            drawHeight = drawWidth / imageAspect;
            drawX = 0;
            drawY = (videoHeight - drawHeight) / 2;
          }

          // ì „í™˜ íš¨ê³¼ ì ìš© (5fps ìµœì í™”)
          const frameInImage = currentFrame - imageStartFrame;
          const transitionFrames = Math.min(3, imageDuration * 0.1); // 0.6ì´ˆ ì „í™˜ì„ 3í”„ë ˆì„ìœ¼ë¡œ

          if (settings.transition === "fade") {
            const opacity =
              frameInImage < transitionFrames
                ? frameInImage / transitionFrames
                : 1;
            ctx.globalAlpha = opacity;
          } else if (settings.transition === "slide") {
            const slideOffset =
              frameInImage < transitionFrames
                ? videoWidth * (1 - frameInImage / transitionFrames)
                : 0;
            drawX += slideOffset;
          } else if (settings.transition === "zoom") {
            const zoomScale =
              frameInImage < transitionFrames
                ? 1 + 0.1 * (1 - frameInImage / transitionFrames)
                : 1;
            const centerX = drawX + drawWidth / 2;
            const centerY = drawY + drawHeight / 2;
            drawX = centerX - (drawWidth * zoomScale) / 2;
            drawY = centerY - (drawHeight * zoomScale) / 2;
            drawWidth *= zoomScale;
            drawHeight *= zoomScale;
          }

          // ì´ë¯¸ì§€ ê·¸ë¦¬ê¸°
          ctx.drawImage(currentImage, drawX, drawY, drawWidth, drawHeight);
          ctx.globalAlpha = 1;

          // ìë§‰ ê·¸ë¦¬ê¸° (ì´ë¯¸ì§€ë³„ ìë§‰)
          const currentSubtitle =
            imageSubtitles && imageSubtitles[currentImageIndex];
          if (currentSubtitle && currentSubtitle.trim()) {
            ctx.fillStyle = "rgba(0, 0, 0, 0.7)";
            ctx.fillRect(0, videoHeight - 80, videoWidth, 80);

            ctx.fillStyle = "#ffffff";
            ctx.font = "bold 32px Arial";
            ctx.textAlign = "center";
            ctx.fillText(currentSubtitle, videoWidth / 2, videoHeight - 30);
          }

          // ë‹¤ìŒ ì´ë¯¸ì§€ë¡œ ì „í™˜ ì²´í¬
          if (
            frameInImage >= imageDuration &&
            currentImageIndex < loadedImages.length - 1
          ) {
            console.log(
              `ğŸ”„ ì´ë¯¸ì§€ ì „í™˜: ${currentImageIndex + 1} â†’ ${
                currentImageIndex + 2
              }`
            );
            currentImageIndex = currentImageIndex + 1;
            imageStartFrame = currentFrame;
          }
        }

        currentFrame++;

        // ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        const progress = Math.min((currentFrame / totalFrames) * 100, 100);
        setGenerationProgress(progress);

        // 10% ë‹¨ìœ„ë¡œ ì§„í–‰ë¥  ë¡œê·¸
        if (currentFrame % Math.floor(totalFrames / 10) === 0) {
          console.log(
            `ğŸ“Š ë Œë”ë§ ì§„í–‰ë¥ : ${Math.round(
              progress
            )}% (${currentFrame}/${totalFrames} í”„ë ˆì„)`
          );
        }

        if (currentFrame < totalFrames) {
          requestAnimationFrame(renderFrame);
        } else {
          // ì˜ìƒ ë…¹í™” ì¢…ë£Œ
          console.log("ğŸ›‘ ë Œë”ë§ ì™„ë£Œ, ë…¹í™” ì¢…ë£Œ ì¤€ë¹„ ì¤‘...");
          setGenerationStatus("Finalizing video recording...");
          setTimeout(() => {
            console.log("ğŸ›‘ MediaRecorder ì •ì§€ ëª…ë ¹ ì‹¤í–‰");
            mediaRecorder.stop();
            if (audioSources.length > 0) {
              console.log(`ğŸµ ${audioSources.length}ê°œ ì˜¤ë””ì˜¤ ì†ŒìŠ¤ ì •ì§€`);
              audioSources.forEach((source, index) => {
                try {
                  source.stop();
                  console.log(`ğŸµ ì˜¤ë””ì˜¤ ì†ŒìŠ¤ ${index + 1} ì •ì§€ ì™„ë£Œ`);
                } catch (e) {
                  console.warn(`ğŸµ ì˜¤ë””ì˜¤ ì†ŒìŠ¤ ${index + 1} ì •ì§€ ì‹¤íŒ¨:`, e);
                }
              });
            }
          }, 1000); // 1ì´ˆ ì¶”ê°€ ëŒ€ê¸°
        }
      };

      // ë Œë”ë§ ì‹œì‘
      renderFrame();
    } catch (error) {
      console.error("Video generation error:", error);
      setGenerationStatus("An error occurred during video generation.");

      // ì‚¬ìš©ìì—ê²Œ ë” ì¹œí™”ì ì¸ ì—ëŸ¬ ë©”ì‹œì§€ í‘œì‹œ
      let errorMessage = "Video generation failed. ";
      if (error.name === "NotSupportedError") {
        errorMessage += "Your browser does not support video recording.";
      } else if (error.name === "NotAllowedError") {
        errorMessage += "Microphone/camera permission is required.";
      } else if (error.message.includes("FFmpeg")) {
        errorMessage += "Failed to load FFmpeg. Please refresh the page.";
      } else {
        errorMessage += "Please try again later.";
      }

      alert(errorMessage);
      setIsGenerating(false); // ì—ëŸ¬ ë°œìƒ ì‹œ ë¡œë”© ì¢…ë£Œ
    } finally {
      // isGeneratingì€ MP4 ë³€í™˜ ì™„ë£Œ ì‹œì ì—ì„œ ì„¤ì •ë¨
      setIsInitializing(false);
      setGenerationProgress(0);
      setConversionProgress(0);
    }
  };

  // FFmpeg ì´ˆê¸°í™”
  const initializeFFmpeg = async () => {
    if (isFFmpegLoaded) {
      console.log("âœ… FFmpeg ì´ë¯¸ ë¡œë“œë¨");
      return ffmpeg;
    }

    console.log("ğŸ”§ FFmpeg ì´ˆê¸°í™” ì‹œì‘...");
    const ffmpegInstance = new FFmpeg();

    try {
      setGenerationStatus("Loading FFmpeg...");
      const baseURL = "https://unpkg.com/@ffmpeg/core@0.12.6/dist/umd";
      console.log(`ğŸ”§ FFmpeg ì½”ì–´ ë‹¤ìš´ë¡œë“œ ì¤‘: ${baseURL}`);

      await ffmpegInstance.load({
        coreURL: await toBlobURL(
          `${baseURL}/ffmpeg-core.js`,
          "text/javascript"
        ),
        wasmURL: await toBlobURL(
          `${baseURL}/ffmpeg-core.wasm`,
          "application/wasm"
        ),
      });

      console.log("âœ… FFmpeg ë¡œë”© ì™„ë£Œ");
      setFFmpeg(ffmpegInstance);
      setIsFFmpegLoaded(true);
      setGenerationStatus("FFmpeg loaded successfully.");
      return ffmpegInstance;
    } catch (error) {
      console.error("âŒ FFmpeg initialization failed:", error);
      setGenerationStatus("Failed to load FFmpeg.");
      throw new Error("FFmpeg loading failed: " + error.message);
    }
  };

  // WebMì„ MP4ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
  const convertWebMToMP4 = async (webmBlob) => {
    try {
      console.log("ğŸ”„ FFmpeg ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°...");
      const ffmpegInstance = await initializeFFmpeg();
      setConversionProgress(20);

      console.log("ğŸ“ WebM íŒŒì¼ì„ FFmpegì— ì“°ê¸°...");
      // WebM íŒŒì¼ì„ FFmpegì— ì“°ê¸°
      await ffmpegInstance.writeFile("input.webm", await fetchFile(webmBlob));
      console.log("âœ… WebM íŒŒì¼ ì“°ê¸° ì™„ë£Œ");
      setConversionProgress(40);

      console.log("ğŸ”„ MP4 ë³€í™˜ ëª…ë ¹ ì‹¤í–‰...");
      // MP4ë¡œ ë³€í™˜ (ì†ë„ ìµœì í™” ì„¤ì •)
      await ffmpegInstance.exec([
        "-i",
        "input.webm",
        "-c:v",
        "libx264",
        "-c:a",
        "aac",
        "-preset",
        "ultrafast", // ê°€ì¥ ë¹ ë¥¸ ë³€í™˜
        "-crf",
        "32", // í’ˆì§ˆë³´ë‹¤ ì†ë„ ìš°ì„  (28 â†’ 32)
        "-profile:v",
        "baseline", // í˜¸í™˜ì„± í–¥ìƒ
        "-level",
        "3.0", // ë‚®ì€ ë ˆë²¨ë¡œ ì†ë„ í–¥ìƒ
        "-movflags",
        "+faststart", // ì›¹ ìµœì í™”
        "-threads",
        "0", // ëª¨ë“  CPU ì½”ì–´ ì‚¬ìš©
        "-y", // ë®ì–´ì“°ê¸° í—ˆìš©
        "output.mp4",
      ]);
      console.log("âœ… MP4 ë³€í™˜ ëª…ë ¹ ì™„ë£Œ");
      setConversionProgress(80);

      console.log("ğŸ“– ë³€í™˜ëœ MP4 íŒŒì¼ ì½ê¸°...");
      // ë³€í™˜ëœ MP4 íŒŒì¼ ì½ê¸°
      const data = await ffmpegInstance.readFile("output.mp4");
      console.log(`âœ… MP4 íŒŒì¼ ì½ê¸° ì™„ë£Œ: ${data.length} bytes`);
      setConversionProgress(90);

      // íŒŒì¼ ì •ë¦¬ (ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ê³„ì† ì§„í–‰)
      try {
        console.log("ğŸ§¹ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì¤‘...");
        await ffmpegInstance.deleteFile("input.webm");
        await ffmpegInstance.deleteFile("output.mp4");
        console.log("âœ… íŒŒì¼ ì •ë¦¬ ì™„ë£Œ");
      } catch (cleanupError) {
        console.warn("âš ï¸ File cleanup failed:", cleanupError);
      }

      const mp4Blob = new Blob([data.buffer], { type: "video/mp4" });
      console.log(`ğŸ‰ MP4 ë³€í™˜ ì™„ë£Œ: ${mp4Blob.size} bytes`);
      return mp4Blob;
    } catch (error) {
      console.error("âŒ MP4 conversion failed:", error);
      // ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì›ë³¸ WebM ë°˜í™˜
      return webmBlob;
    }
  };

  const handleDownload = () => {
    if (generatedVideoUrl) {
      const link = document.createElement("a");
      link.href = generatedVideoUrl;
      link.download = "slide-video.mp4"; // MP4 í˜•ì‹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ
      document.body.appendChild(link);
      link.click();
      document.body.removeChild(link);
    }
  };

  const getTotalDuration = () => {
    return images.length * settings.duration;
  };

  const formatTime = (seconds) => {
    const mins = Math.floor(seconds / 60);
    const secs = Math.floor(seconds % 60);
    return `${mins}:${secs.toString().padStart(2, "0")}`;
  };

  return (
    <div>
      <h3 className="text-lg font-semibold text-gray-800 mb-4">
        <i className="fas fa-download mr-2 text-green-500"></i>
        Generate Video
      </h3>

      {/* ì˜ìƒ ìƒì„± ìƒíƒœ */}
      {!generatedVideoUrl ? (
        <div className="space-y-6">
          {/* ìƒì„±í•  ì˜ìƒ ì •ë³´ ìš”ì•½ */}
          <div className="bg-gray-50 rounded-lg p-4">
            <h4 className="text-md font-medium text-gray-700 mb-3">
              Video Information
            </h4>
            <div className="grid grid-cols-2 gap-4 text-sm">
              <div className="flex items-center space-x-2">
                <i className="fas fa-images text-green-500"></i>
                <span>Images: {images.length}</span>
              </div>
              <div className="flex items-center space-x-2">
                <i className="fas fa-clock text-green-500"></i>
                <span>Duration: {formatTime(getTotalDuration())}</span>
              </div>
              <div className="flex items-center space-x-2">
                <i className="fas fa-video text-green-500"></i>
                <span>Resolution: 854Ã—480 (5fps)</span>
              </div>
              <div className="flex items-center space-x-2">
                <i className="fas fa-magic text-green-500"></i>
                <span>
                  Effect:{" "}
                  {settings.transition === "fade"
                    ? "Fade"
                    : settings.transition}
                </span>
              </div>
              <div className="flex items-center space-x-2">
                <i className="fas fa-music text-green-500"></i>
                <span>
                  Music:{" "}
                  {musicFiles && musicFiles.length > 0
                    ? `${musicFiles.length} files`
                    : "No"}
                </span>
              </div>
            </div>
            {subtitle && (
              <div className="mt-3 pt-3 border-t border-gray-200">
                <div className="flex items-center space-x-2">
                  <i className="fas fa-font text-green-500"></i>
                  <span className="text-sm">Subtitles: {subtitle}</span>
                </div>
              </div>
            )}
          </div>

          {/* ìƒì„± ë²„íŠ¼ */}
          <div className="text-center">
            <button
              onClick={handleGenerateVideo}
              disabled={images.length === 0 || isGenerating}
              className="bg-green-500 text-white px-8 py-4 rounded-lg hover:bg-green-600 disabled:bg-gray-300 disabled:cursor-not-allowed transition-colors duration-200 text-lg font-medium"
            >
              {isGenerating ? (
                <>
                  <i className="fas fa-spinner fa-spin mr-2"></i>
                  Generating Video...
                </>
              ) : (
                <>
                  <i className="fas fa-video mr-2"></i>
                  Generate Video
                </>
              )}
            </button>

            {/* ì§„í–‰ ìƒíƒœ í‘œì‹œ */}
            {isGenerating && (
              <div className="mt-4 p-4 bg-blue-50 border border-blue-200 rounded-lg">
                <div className="flex items-center justify-center space-x-2 text-blue-600 mb-2">
                  <i className="fas fa-cog fa-spin"></i>
                  <span className="font-medium">Processing Video</span>
                </div>
                <p className="text-sm text-blue-600 text-center">
                  {generationStatus || "Initializing video generation..."}
                </p>
                {conversionProgress > 0 && (
                  <div className="mt-3">
                    <div className="flex justify-between text-sm text-gray-600 mb-1">
                      <span>MP4 Conversion</span>
                      <span>{Math.round(conversionProgress)}%</span>
                    </div>
                    <div className="w-full bg-gray-200 rounded-full h-2">
                      <div
                        className="bg-blue-500 h-2 rounded-full transition-all duration-300"
                        style={{ width: `${conversionProgress}%` }}
                      ></div>
                    </div>
                  </div>
                )}

                {/* ì§„í–‰ë¥  ë°” */}
                <div className="mt-4">
                  <div className="flex justify-between text-sm text-gray-600 mb-1">
                    <span>Progress</span>
                    <span>{Math.round(generationProgress)}%</span>
                  </div>
                  <div className="w-full bg-gray-200 rounded-full h-2">
                    <div
                      className="bg-blue-500 h-2 rounded-full transition-all duration-300"
                      style={{ width: `${generationProgress}%` }}
                    ></div>
                  </div>
                </div>
              </div>
            )}

            {!isGenerating && (
              <>
                <p className="text-sm text-gray-500 mt-2">
                  Video generation is processed in the browser
                </p>
                {!isFFmpegLoaded && (
                  <p className="text-xs text-blue-600 mt-1">
                    <i className="fas fa-info-circle mr-1"></i>
                    First generation may take longer due to FFmpeg loading
                  </p>
                )}

                {/* ê²½ê³  ë¬¸êµ¬ */}
                <div className="mt-4 p-3 bg-yellow-50 border border-yellow-200 rounded-lg">
                  <div className="flex items-center space-x-2 text-yellow-700">
                    <i className="fas fa-exclamation-triangle"></i>
                    <span className="text-sm font-medium">Important</span>
                  </div>
                  <p className="text-xs text-yellow-600 mt-1">
                    Do not close the browser or refresh the page during video
                    generation.
                  </p>
                </div>
              </>
            )}
          </div>
        </div>
      ) : (
        /* ìƒì„± ì™„ë£Œ ìƒíƒœ */
        <div className="space-y-6">
          <div className="text-center">
            <div className="inline-flex items-center space-x-2 text-green-600 mb-4">
              <i className="fas fa-check-circle text-2xl"></i>
              <span className="text-lg font-medium">Video Generated!</span>
            </div>
            <p className="text-gray-600">
              Your video has been successfully generated.
            </p>
          </div>

          {/* ì˜ìƒ ë¯¸ë¦¬ë³´ê¸° */}
          <div className="bg-gray-900 rounded-lg p-4">
            <h4 className="text-white text-lg font-medium mb-3">Preview</h4>
            <video
              src={generatedVideoUrl}
              controls
              className="w-full rounded-lg"
              style={{ maxHeight: "400px" }}
            >
              Your browser does not support the video tag.
            </video>
          </div>

          {/* ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ */}
          <div className="text-center">
            <button
              onClick={handleDownload}
              className="bg-green-500 text-white px-8 py-4 rounded-lg hover:bg-green-600 transition-colors duration-200 text-lg font-medium"
            >
              <i className="fas fa-download mr-2"></i>
              Download Video
            </button>
          </div>

          {/* ìƒˆ ì˜ìƒ ë§Œë“¤ê¸° */}
          <div className="text-center">
            <button
              onClick={() => {
                setGeneratedVideoUrl(null);
                setGenerationProgress(0);
                setConversionProgress(0);
                setGenerationStatus("");
                setIsInitializing(false);
              }}
              className="bg-gray-500 text-white px-6 py-2 rounded-lg hover:bg-gray-600 transition-colors duration-200"
            >
              <i className="fas fa-plus mr-2"></i>
              Create New Video
            </button>
          </div>
        </div>
      )}

      {/* ì£¼ì˜ì‚¬í•­ */}
      <div className="mt-6">
        <div className="bg-yellow-50 border border-yellow-200 rounded-lg p-4">
          <div className="flex items-start space-x-3">
            <i className="fas fa-exclamation-triangle text-yellow-500 mt-1"></i>
            <div>
              <p className="text-sm text-yellow-800 font-medium">
                Important Notes
              </p>
              <ul className="text-xs text-yellow-700 mt-1 space-y-1">
                <li>
                  â€¢ Video generation is optimized for slideshow (480p, 5fps)
                </li>
                <li>
                  â€¢ MP4 format is generated directly when supported by browser
                </li>
                <li>
                  â€¢ WebM format is used as fallback for better compatibility
                </li>
                <li>â€¢ Audio and video are synchronized during generation</li>
                <li>
                  â€¢ All processing is done in the browser - no server upload
                </li>
                <li>
                  â€¢ Generation speed improved by 10-15x for slideshow videos
                </li>
                <li>â€¢ 5fps is perfect for static image slideshows</li>
              </ul>
            </div>
          </div>
        </div>
      </div>

      {/* ë²„íŠ¼ë“¤ */}
      <div className="mt-6 flex justify-between">
        <button
          onClick={onPrev}
          disabled={isGenerating}
          className="bg-gray-500 text-white px-6 py-2 rounded-lg hover:bg-gray-600 disabled:bg-gray-300 disabled:cursor-not-allowed transition-colors duration-200"
        >
          <i className="fas fa-arrow-left mr-2"></i>
          Previous
        </button>

        {generatedVideoUrl && (
          <button
            onClick={() => {
              setGeneratedVideoUrl(null);
              setGenerationProgress(0);
              setConversionProgress(0);
              setGenerationStatus("");
              setIsInitializing(false);
            }}
            className="bg-blue-500 text-white px-6 py-2 rounded-lg hover:bg-blue-600 transition-colors duration-200"
          >
            <i className="fas fa-redo mr-2"></i>
            Regenerate
          </button>
        )}
      </div>
    </div>
  );
}
